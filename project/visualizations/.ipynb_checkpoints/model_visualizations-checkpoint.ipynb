{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Model Visualizations"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Notebook Summary:\n",
    "\n",
    "#### Objective: provide visualizations to compare all modeling steps outcomes \n",
    "\n",
    "* Please go to the \"modeling\" directory to locate the relevant notebooks\n",
    "* Relevant notebook names: \"baseline_regression\", \"new_baseline_regression\", \"poly_regressions\", \"regularization\", \"ensembles\"\n",
    "* Models compared are: \n",
    "    * The initial Linear Regression baseline model\n",
    "    * The new Linear Regression baseline after feature extraction, transformation, binarization, and ETL\n",
    "    * Decision Tree, Support Vector, and KNN regressions\n",
    "    * Linear Regression after adding interactions\n",
    "    * Linear Regressions after adding interactions and performing feature selection\n",
    "    * Lasso, Ridge, and Elastic Net regressions\n",
    "    * Random Forest, Bagging, Adaboost, Gradient Boosting ensemble regressions\n",
    "\n",
    "#### Conclusions: \n",
    "* We choose the tuned Lasso model for the best trade off between bias and variance "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Plot for First Batch of Regressions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "X = ['Linear', 'Decision Tree', 'Support Vector', 'KNN', 'Linear w Interactions', 'Linear w Feature Sel','Quadratic']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "train_errors = [np.sqrt(-scores_lin['train_neg_mean_squared_error'].mean()),\n",
    "                np.sqrt(-scores_tree['train_neg_mean_squared_error'].mean())+.001,\n",
    "                np.sqrt(-gs_results_svreg['mean_train_score'].mean()),\n",
    "                np.sqrt(-gs_results_nn['mean_train_score'].mean()), \n",
    "                np.sqrt(-scores_lin_intonly['train_neg_mean_squared_error'].mean())+.001, \n",
    "                np.sqrt(-scores_lin_ratios['train_neg_mean_squared_error'].mean()),\n",
    "                np.sqrt(-scores_lin_ratios_fsel['train_neg_mean_squared_error'].mean()),\n",
    "                np.sqrt(-scores_quad['train_neg_mean_squared_error'].mean())+.001]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "val_errors = [np.sqrt(-scores_lin['test_neg_mean_squared_error'].mean()),\n",
    "              np.sqrt(-scores_tree['test_neg_mean_squared_error'].mean()),\n",
    "              np.sqrt(-gs_results_svreg['mean_test_score'].mean()),\n",
    "              np.sqrt(-gs_results_nn['mean_test_score'].mean()),\n",
    "              np.sqrt(-scores_lin_intonly['test_neg_mean_squared_error'].mean()),\n",
    "              np.sqrt(-scores_lin_ratios['test_neg_mean_squared_error'].mean()), \n",
    "              np.sqrt(-scores_lin_ratios_fsel['test_neg_mean_squared_error'].mean()),\n",
    "              np.sqrt(-scores_quad['test_neg_mean_squared_error'].mean())]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "test_errors = [lin_reg_rmse_test,\n",
    "            np.sqrt(mean_squared_error(y_test, test_predictions_tree_reg)),\n",
    "            np.sqrt(mean_squared_error(y_test, test_predictions_best_model_svr)),\n",
    "            np.sqrt(mean_squared_error(y_test, test_predictions_best_model_kneigh)),\n",
    "            np.sqrt(mean_squared_error(y_test_intonly, test_predictions_lin_reg_intonly)),\n",
    "            test_lin_ratios_nofs,\n",
    "            np.sqrt(mean_squared_error(y_test, test_predictions_ratios_lin_reg)),\n",
    "            np.sqrt(mean_squared_error(y_test_quad, test_predictions_quad_reg))]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "ax = plt.subplot(111)\n",
    "x1 = [i-0.2 for i in range(len(train_errors))]\n",
    "x2 = [i for i in range(len(train_errors))]\n",
    "x3 = [i+0.2 for i in range(len(train_errors))]\n",
    "ax.bar(x1, train_errors, width=0.2, color='b', align='center')\n",
    "ax.bar(x2, val_errors, width=0.2, color='g', align='center')\n",
    "ax.bar(x3, test_errors, width=0.2, color='r', align='center')\n",
    "ax.set_xticklabels(X)\n",
    "ax.xaxis.set_major_locator(ticker.FixedLocator([i-0.05 for i in x2]))\n",
    "ax.set_xlabel('Models')\n",
    "ax.set_ylabel('RMSE')\n",
    "ax.set_title('Regression Models Comparison')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Plot for Regularized Regressions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "np.sqrt(-scores_quad['train_neg_mean_squared_error'].mean())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "X = ['Lasso', 'Ridge', 'Elastic Net']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "train_errors = [train_scores_lasso.mean(), train_scores_ridge.mean(), train_scores_en.mean()]\n",
    "val_errors = [val_scores_lasso.mean(), val_scores_ridge.mean(), val_scores_en.mean()]\n",
    "test_errors = [np.sqrt(mean_squared_error(y_test, test_predictions_lasso)),\n",
    "               np.sqrt(mean_squared_error(y_test, test_predictions_ridge)), \n",
    "               np.sqrt(mean_squared_error(y_test, test_predictions_en))]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "np.sqrt(mean_squared_error(y_test, test_predictions_lasso))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "ax = plt.subplot(111)\n",
    "x1 = [i-0.2 for i in range(len(train_errors))]\n",
    "x2 = [i for i in range(len(train_errors))]\n",
    "x3 = [i+0.2 for i in range(len(train_errors))]\n",
    "ax.bar(x1, train_errors, width=0.2, color='b', align='center')\n",
    "ax.bar(x2, val_errors, width=0.2, color='g', align='center')\n",
    "ax.bar(x3, test_errors, width=0.2, color='r', align='center')\n",
    "ax.set_xticklabels(X)\n",
    "ax.xaxis.set_major_locator(ticker.FixedLocator([i-0.05 for i in x2]))\n",
    "ax.set_xlabel('Models')\n",
    "ax.set_ylabel('RMSE')\n",
    "ax.set_title('Regularized Models Comparison')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Plot for Ensembles"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "X = ['Random Forest', 'Bagging', 'AdaBoost', 'Gradient Boosting']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "np.sqrt(-best_rfr_scores['train_neg_mean_squared_error'].mean())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "train_errors = [np.sqrt(-best_rfr_scores['train_neg_mean_squared_error'].mean()),\n",
    "                train_scores_br.mean(),\n",
    "                train_scores_abr.mean(),\n",
    "                train_scores_gbr.mean()]\n",
    "\n",
    "val_errors = [np.sqrt(-best_rfr_scores['test_neg_mean_squared_error'].mean()),\n",
    "              val_scores_br.mean(),\n",
    "              val_scores_abr.mean(),\n",
    "              val_scores_gbr.mean()]\n",
    "\n",
    "test_errors = [np.sqrt(mean_squared_error(y_test, test_predictions_rf)),\n",
    "               np.sqrt(mean_squared_error(y_test, test_predictions_br)),\n",
    "               np.sqrt(mean_squared_error(y_test, test_predictions_abr)),\n",
    "               np.sqrt(mean_squared_error(y_test, test_predictions_gbr))]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import matplotlib.ticker as ticker\n",
    "ax = plt.subplot(111)\n",
    "x1 = [i-0.2 for i in range(len(train_errors))]\n",
    "x2 = [i for i in range(len(train_errors))]\n",
    "x3 = [i+0.2 for i in range(len(train_errors))]\n",
    "ax.bar(x1, train_errors, width=0.2, color='b', align='center')\n",
    "ax.bar(x2, val_errors, width=0.2, color='g', align='center')\n",
    "ax.bar(x3, test_errors, width=0.2, color='r', align='center')\n",
    "ax.set_xticklabels(X)\n",
    "ax.xaxis.set_major_locator(ticker.FixedLocator([i-0.05 for i in x2]))\n",
    "ax.set_xlabel('Models')\n",
    "ax.set_ylabel('RMSE')\n",
    "ax.set_title('Ensembles Comparison')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Ensemble Regression Models"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.14"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
