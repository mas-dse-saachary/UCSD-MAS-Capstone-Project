{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# New Baseline Regression Models with Transformed Data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Modeling Step 3"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Notebook Summary:\n",
    "\n",
    "#### Objective: improve the new baseline model to predict AirBnB listing prices by trying Nonlinear Regression models, or adding 200 features obtained from calculating ratios between existing features and then performing Feature Selection with Recursive Feature Elimination\n",
    "\n",
    "* Nonlinear attempts consist of first modeling only with interaction features, and then modeling with quadratic terms \n",
    "* Features to be used to calculate ratios were selected arbitrarily, focusing on distance features (e.g. distance to ocean, distance to closest city recreation site, etc.) and count features (e.g. count of events within 1 KM vs count of parks within 1 KM) \n",
    "\n",
    "#### Conclusions: \n",
    "* Nonlinear attempts are highly computationally expensive and perform poorly in terms of model accuracy \n",
    "* Adding ratio features provides a small improvement to the baseline model picked in the \"new_baseline_model\" notebook \n",
    "* Performing feature selection with RFECV on the expanded dataset identifies 147 features as the optimal set that minimizes validation RMSE, but the new performance metrics show slightly lower accuracy. Despite that, we prefer to use this smaller set of features as it provides a much simpler model i.e. a model with 100 ca. less features  \n",
    "* ##### Linear Regression with the expanded but then \"selected\" dataset is therefore our new best model\n",
    "\n",
    "#### Next Steps: \n",
    "###### In the regularization notebook we use Lasso, Ridge and Elastic Net Regression models in order to further improve our model by simplifying it while also not giving up accuracy results obtained thus far"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import seaborn as sb\n",
    "import matplotlib.pyplot as plt\n",
    "from pandas.plotting import scatter_matrix\n",
    "import matplotlib.cm as cm\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from sklearn import linear_model\n",
    "from sklearn.metrics import r2_score, mean_squared_error,mean_absolute_error\n",
    "from sklearn.model_selection import KFold,cross_val_predict,cross_val_score, cross_validate, train_test_split, GridSearchCV\n",
    "from sklearn.preprocessing import LabelEncoder, LabelBinarizer, PolynomialFeatures, MinMaxScaler, StandardScaler\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn import preprocessing\n",
    "from sklearn.neighbors import LocalOutlierFactor, KNeighborsRegressor\n",
    "from sklearn.feature_selection import RFE, f_regression, RFECV\n",
    "from sklearn.ensemble import RandomForestRegressor, BaggingRegressor, AdaBoostRegressor, GradientBoostingRegressor\n",
    "from sklearn.tree import DecisionTreeRegressor\n",
    "from sklearn.svm import SVR"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/pauldefusco/anaconda2/envs/py27/lib/python2.7/site-packages/statsmodels/compat/pandas.py:56: FutureWarning: The pandas.core.datetools module is deprecated and will be removed in a future version. Please use the pandas.tseries module instead.\n",
      "  from pandas.core import datetools\n"
     ]
    }
   ],
   "source": [
    "import sys\n",
    "sys.path.append('./../lib')\n",
    "from airbnb_modeling import detect_feature_importance, scale_data, normalize_data, eval_metrics, plot_residuals, plot_predictions\n",
    "from parse_methods import parse_columns\n",
    "from airbnb_modeling import detect_interactions, add_interactions, map_variable, plot_rmse_instances,plot_rmse_features, plot_accuracy_instances"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "%store -r scores_lin \n",
    "%store -r scores_tree \n",
    "%store -r scores_sv_reg \n",
    "%store -r scores_neigh_reg"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "%store -r best_model_svr \n",
    "%store -r best_model_kneigh \n",
    "%store -r best_model_dtree \n",
    "%store -r lin_reg"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "%store -r X_ratios\n",
    "%store -r X_normed\n",
    "%store -r X_test\n",
    "%store -r y_normed\n",
    "%store -r y_test\n",
    "%store -r listings"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Feature Interactions - We do this in two ways - first we check and add the interactions that increase accuracy beyond an arbitrary threshold (0.02); Then, we just add all interactions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/pauldefusco/anaconda2/envs/py27/lib/python2.7/site-packages/sklearn/linear_model/base.py:509: RuntimeWarning: internal gelsd driver lwork query error, required iwork dimension not returned. This is likely the result of LAPACK bug 0038, fixed in LAPACK 3.2.2 (released July 21, 2010). Falling back to 'gelss' driver.\n",
      "  linalg.lstsq(X, y)\n"
     ]
    }
   ],
   "source": [
    "increments = detect_interactions(X_normed,y_normed, 0.02)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "X_normed_wint = add_interactions(X_normed, increments)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(0, 3)"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "increments.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The above did not return any interactions! That means the interactions are probably not going to make large changes to our models above"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "poly = PolynomialFeatures(interaction_only=True)\n",
    "X_normed_wint = poly.fit_transform(X_normed)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "X_train, X_test, y_train, y_test = train_test_split(X_normed_wint,y_normed, test_size=0.3, random_state=42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "LinearRegression(copy_X=True, fit_intercept=True, n_jobs=1, normalize=False)"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "lin_reg_intonly = linear_model.LinearRegression(fit_intercept=True, normalize=False)\n",
    "lin_reg_intonly.fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "scores_lin_intonly = cross_validate(lin_reg_intonly, X_train, y_train, cv=10, return_train_score=True,\n",
    "                         scoring=('r2', 'neg_mean_squared_error','neg_mean_absolute_error'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "print 'Evaluation Metrics for Linear Regression with CV - Interactions Only Added: '\n",
    "eval_metrics(scores_lin_intonly)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#No need for plot here\n",
    "#plot_rmse_instances(lin_reg_intonly, X_train, y_train)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Adding interactions simply overfits. Let's also try adding quadratic terms to the normalized dataset to see if nonlinaer regression might help, although it will probably also overfit"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "poly = PolynomialFeatures(2)\n",
    "X_normed_quad = poly.fit_transform(X_normed)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "X_train, X_test, y_train, y_test = train_test_split(X_normed_quad,y_normed, test_size=0.3, random_state=42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "quad_reg = linear_model.LinearRegression(fit_intercept=True, normalize=False)\n",
    "quad_reg.fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "scores_quad = cross_validate(quad_reg, X_train, y_train, cv=5, return_train_score=True,\n",
    "                         scoring=('r2', 'neg_mean_squared_error','neg_mean_absolute_error'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "print 'Evaluation Metrics for Linear Regression with CV - Interactions Only Added: '\n",
    "eval_metrics(scores_quad)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#plot_rmse_instances(quad_reg, X_train, y_train)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Despite all the attempts, the most promising model is Linear Regression. Let's try the same Linear Regression with the ratios features. We are probably going to overfit again but we will then do Feature Selection: the goal is to choose a good feature subset "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "X_train, X_test, y_train, y_test = train_test_split(X_ratios, y_normed, test_size=0.3, random_state=42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "lin_reg = linear_model.LinearRegression(fit_intercept=True, normalize=False)\n",
    "lin_reg.fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "scores_lin_ratios = cross_validate(lin_reg, X_train, y_train, cv=10, return_train_score=True,\n",
    "                         scoring=('r2', 'neg_mean_squared_error','neg_mean_absolute_error'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "print 'Evaluation Metrics for Linear Regression with CV: '\n",
    "eval_metrics(scores_lin_ratios)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "temp_pred = lin_reg.predict(X_test)\n",
    "test_lin_ratios_nofs = np.sqrt(-mean_squared_error(y_test, temp_pred))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The model above is promising: the training RMSE has increased more than the validation RMSE, which is a sign that we may be approaching the sweet spot and getting close to starting to overfit"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Feature Selection - We use this promising model above to pick only the best features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "selector = RFECV(lin_reg, step=1, cv=5, scoring='neg_mean_squared_error')\n",
    "selector.fit(X_ratios, y_normed)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "print(\"Optimal number of features : %d\" % selector.n_features_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Plot number of features VS. cross-validation scores\n",
    "plt.figure()\n",
    "plt.xlabel(\"Number of features selected\")\n",
    "plt.ylabel(\"Cross validation RMSE score\")\n",
    "plt.title(\"Optimal number of features : %d\" % selector.n_features_)\n",
    "plt.plot(range(1, len(selector.grid_scores_) + 1), np.sqrt(-selector.grid_scores_))\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "X_new = selector.transform(X_ratios)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "All features have equally important ranking!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "selector.ranking_"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now let's rerun our best model so far and evaluate changes to model metrics resulting from removing unneeded features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "X_train, X_test, y_train, y_test = train_test_split(X_new, y_normed, test_size=0.3, random_state=42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "lin_reg = linear_model.LinearRegression(fit_intercept=True, normalize=False)\n",
    "lin_reg.fit(X_train,y_train)\n",
    "scores_temp = cross_validate(lin_reg, X_train, y_train, cv=10, return_train_score=True,\n",
    "                         scoring=('r2', 'neg_mean_squared_error','neg_mean_absolute_error'))\n",
    "print 'Evaluation Metrics for Linear Regression with CV: '\n",
    "eval_metrics(scores_temp)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The validation RMSE has actually increased, while the accuracy has decreased slightly - this is bad but we make the choice to trade off a little bit of accuracy in order to shed complexity (we are losing more than 100 features this way)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "Now we rebuild the model only with the important features i.e. number of features where val error is lowest - we do this in order to replicate what we created above with RFECV"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "X_train, X_test, y_train, y_test = train_test_split(X_ratios, y_normed, test_size=0.3, random_state=42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "feats = {} # a dict to hold feature_name: feature_importance\n",
    "for feature, importance in zip(X_normed.columns, selector.ranking_):\n",
    "    feats[feature] = importance #add the name/value pair \n",
    "\n",
    "importances = pd.DataFrame.from_dict(feats, orient='index').rename(columns={0: 'RFECV_Ranking'})\n",
    "importances = importances.sort_values(by='RFECV_Ranking')\n",
    "importances.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We are restricting our features to the ones that minimize CV RMSE by feeding the new data into RFECV"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "best_features = list(importances.head(selector.n_features_).index)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "lin_reg = linear_model.LinearRegression(fit_intercept=True, normalize=False)\n",
    "lin_reg.fit(X_train[best_features],y_train)\n",
    "scores_lin_ratios_fsel = cross_validate(lin_reg, X_train[best_features], y_train, cv=10, \n",
    "                         scoring=('r2', 'neg_mean_squared_error','neg_mean_absolute_error'))\n",
    "print 'Evaluation Metrics for Linear Regression with CV: '\n",
    "eval_metrics(scores_lin_ratios_fsel)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "plot_rmse_features(lin_reg, X_train, y_train, best_features)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Finally, let's see how the models performs against our Test Set"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "X_train, X_test, y_train, y_test = train_test_split(X_normed, y_normed, test_size=0.3, random_state=42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "X_train_intonly, X_test_intonly, y_train_intonly, y_test_intonly = train_test_split(X_normed_wint,y_normed, test_size=0.3, random_state=42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "X_train_quad, X_test_quad, y_train_quad, y_test_quad = train_test_split(X_normed_quad,y_normed, test_size=0.3, random_state=42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "test_predictions_lin_reg_intonly = lin_reg_intonly.predict(X_test_intonly)\n",
    "test_predictions_quad_reg = quad_reg.predict(X_test_quad)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "print 'Evaluation Metrics for Linear Regression with Interactions'\n",
    "print 'Test R2: ',r2_score(y_test, test_predictions_lin_reg_intonly)\n",
    "print 'Test RMSE: ',np.sqrt(mean_squared_error(y_test_intonly, test_predictions_lin_reg_intonly))\n",
    "print 'Test MAE: ',mean_absolute_error(y_test_intonly, test_predictions_lin_reg_intonly)\n",
    "map_variable(y_test_intonly-test_predictions_lin_reg_intonly, listings)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "print 'Evaluation Metrics for Quadratic Regression without Interactions'\n",
    "print 'Test R2: ',r2_score(y_test_quad, test_predictions_quad_reg)\n",
    "print 'Test RMSE: ',np.sqrt(mean_squared_error(y_test_quad, test_predictions_quad_reg))\n",
    "print 'Test MAE: ',mean_absolute_error(y_test_quad, test_predictions_quad_reg)\n",
    "map_variable(y_test_quad-test_predictions_quad_reg, listings)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from yellowbrick.regressor import ResidualsPlot"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Takes too long\n",
    "#lin_reg_intonly_pred_cv = cross_val_predict(lin_reg_intonly, X_train_intonly, y_train_intonly, cv=10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "\"\"\"plt.scatter(lin_reg_intonly_pred_cv, lin_reg_intonly_pred_cv-y_train_intonly, \n",
    "            c='steelblue', marker='o', edgecolor='white',\n",
    "           label='CV Train Data')\n",
    "plt.scatter(test_predictions_lin_reg_intonly, test_predictions_lin_reg_intonly-y_test_intonly, \n",
    "            c='limegreen', marker='x', edgecolor='red',\n",
    "           label='Test Data')\n",
    "plt.xlabel('Predicted Values')\n",
    "plt.ylabel('Residuals')\n",
    "plt.legend(loc='upper right')\n",
    "plt.hlines(y=0, color='black', xmin=y_train_intonly.min()-1, xmax=y_train_intonly.max()+1, lw=3)\n",
    "plt.title('Predicted Values vs Residuals - Linear Regression with Interactions')\n",
    "plt.show()\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#Takes too long\n",
    "#quad_reg_pred_cv = cross_val_predict(quad_reg, X_train_quad, y_train_quad, cv=10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "\"\"\"plt.scatter(quad_reg_pred_cv, quad_reg_pred_cv-y_train_quad, \n",
    "            c='steelblue', marker='o', edgecolor='white',\n",
    "           label='CV Train Data')\n",
    "plt.scatter(test_predictions_quad_reg, test_predictions_quad_reg-y_test_quad, \n",
    "            c='limegreen', marker='x', edgecolor='red',\n",
    "           label='CV Test Data')\n",
    "plt.xlabel('Predicted Values')\n",
    "plt.ylabel('Residuals')\n",
    "plt.legend(loc='upper right')\n",
    "plt.hlines(y=0, color='black', xmin=y_train_intonly.min()-1, xmax=y_train_intonly.max()+1, lw=3)\n",
    "plt.title('Predicted Values vs Residuals - Quadratic Regression')\n",
    "plt.show()\"\"\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Best model After Adding Ratios and Doing Feature Selection"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "X_train, X_test, y_train, y_test = train_test_split(X_ratios, y_normed, test_size=0.3, random_state=42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "lin_reg = linear_model.LinearRegression(fit_intercept=True, normalize=False)\n",
    "lin_reg.fit(X_train, y_train)\n",
    "test_predictions_ratios_lin_reg_fs = lin_reg.predict(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "print 'Evaluation Metrics for Linear Regression with Ratio Features & Feature Selection'\n",
    "print 'Test R2: ',r2_score(y_test, test_predictions_ratios_lin_reg_fs)\n",
    "print 'Test RMSE: ',np.sqrt(mean_squared_error(y_test, test_predictions_ratios_lin_reg_fs))\n",
    "print 'Test MAE: ',mean_absolute_error(y_test, test_predictions_ratios_lin_reg_fs)\n",
    "map_variable(y_test-test_predictions_ratios_lin_reg_fs, listings)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "ratios_lin_reg_pred_cv = cross_val_predict(lin_reg, X_train, y_train, cv=10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "plt.scatter(ratios_lin_reg_pred_cv, ratios_lin_reg_pred_cv-y_train, \n",
    "            c='steelblue', marker='o', edgecolor='white',\n",
    "           label='CV Train Data')\n",
    "plt.scatter(test_predictions_ratios_lin_reg, test_predictions_ratios_lin_reg-y_test, \n",
    "            c='limegreen', marker='x', edgecolor='red',\n",
    "           label='Test Data')\n",
    "plt.xlabel('Predicted Values')\n",
    "plt.ylabel('Residuals')\n",
    "plt.legend(loc='upper right')\n",
    "plt.hlines(y=0, color='black', xmin=-.3, xmax=.4, lw=3)\n",
    "plt.title('Predicted Values vs Residuals - Linear Regression with Ratio Features & Feature Selection')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#%store scores_lin, scores_tree, scores_sv_reg, scores_neigh_reg"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "%store scores_lin_intonly\n",
    "%store scores_lin_ratios\n",
    "%store scores_lin_ratios_fsel\n",
    "%store scores_quad"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "%store test_predictions_ratios_lin_reg_fs\n",
    "%store test_predictions_lin_reg_intonly\n",
    "%store test_predictions_quad_reg"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.14"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
