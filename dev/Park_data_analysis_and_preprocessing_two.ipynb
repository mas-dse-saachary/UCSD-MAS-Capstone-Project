{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import json\n",
    "from StringIO import StringIO\n",
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\sanka\\Anaconda2\\lib\\site-packages\\sklearn\\cross_validation.py:41: DeprecationWarning: This module was deprecated in version 0.18 in favor of the model_selection module into which all the refactored classes and functions are moved. Also note that the interface of the new CV iterators are different from that of this module. This module will be removed in 0.20.\n",
      "  \"This module will be removed in 0.20.\", DeprecationWarning)\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import os\n",
    "import sklearn as sk\n",
    "from sklearn.linear_model import MultiTaskLasso, MultiTaskElasticNet, ElasticNet\n",
    "from sklearn.cross_validation import train_test_split\n",
    "from sklearn.metrics import mean_absolute_error, mean_squared_error\n",
    "import sklearn.metrics as skmet\n",
    "import numpy as np\n",
    "import nltk\n",
    "from nltk.tokenize import sent_tokenize, word_tokenize\n",
    "from nltk.corpus import stopwords, names\n",
    "import datetime\n",
    "from scipy.stats import ttest_ind \n",
    "import csv"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import findspark\n",
    "findspark.init()\n",
    "\n",
    "from pyspark import SparkContext\n",
    "#sc.stop()\n",
    "## add after creating spark_PCA.py\n",
    "sc = SparkContext(master=\"local[3]\") \n",
    "from pyspark import SparkContext\n",
    "from pyspark.sql import *\n",
    "sqlContext = SQLContext(sc)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from pyspark.sql import Row\n",
    "from pyspark.sql.types import *"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "listings = pd.read_csv('inside_airbnb/listings.csv')\n",
    "list_summ = pd.read_csv('inside_airbnb/listings_summ.csv')\n",
    "neighborhoods = pd.read_csv('inside_airbnb/neighbourhoods.csv')\n",
    "reviews = pd.read_csv('inside_airbnb/reviews.csv')\n",
    "reviews_summ = pd.read_csv('inside_airbnb/reviews_summ.csv')\n",
    "calendar = pd.read_csv('inside_airbnb/calendar.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "park_data = pd.read_json('Datasources/other general/parks_datasd.geojson', orient = 'records')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "df_geo = pd.DataFrame()\n",
    "count = 0\n",
    "\n",
    "for idx in park_data.index:\n",
    "    k = pd.DataFrame.from_dict({count: {'center_x': park_data['features'][idx]['properties']['center_x'], \n",
    "                                            'center_y': park_data['features'][idx]['properties']['center_y'],\n",
    "                                             }}, orient = 'index')\n",
    "    df_geo = df_geo.append(k)\n",
    "    \n",
    "    count = count + 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "schema = StructType([StructField(\"id\", IntegerType(), True),\n",
    "                    StructField(\"longitude\", DoubleType(), True),\n",
    "                    StructField(\"latitude\", DoubleType(), True)])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "schema_two = StructType([StructField(\"park_id\", IntegerType(), True),\n",
    "                    StructField(\"park_longitude\", DoubleType(), True),\n",
    "                    StructField(\"park_latitude\", DoubleType(), True)])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "spql_listings_info = sqlContext.createDataFrame(listings[['id', 'longitude', 'latitude']], schema)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "df_geo['park_id'] = range(len(df_geo))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "spql_parks_info = sqlContext.createDataFrame(df_geo[['park_id', 'center_x', 'center_y']], schema_two)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "spql_listings_info_rdd = spql_listings_info.rdd.map(lambda row:(row.id, row.longitude,row.latitude))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "spql_parks_info_rdd = spql_parks_info.rdd.map(lambda row:(row.park_id, row.park_longitude,row.park_latitude))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "spql_listings_and_parks_info_rdd = spql_listings_info_rdd.cartesian(spql_parks_info_rdd)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "spql_listings_and_parks_info_rdd = spql_listings_and_parks_info_rdd.map(lambda x: (x[0][0], x[0][1], x[0][2], x[1][0], x[1][1], x[1][2]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def distance_calculation(x):\n",
    "        p_one = float(x[2])\n",
    "        q_one = float(x[1])\n",
    "        p_two = float(x[5])\n",
    "        q_two = float(x[4])\n",
    "        lon_diff = (q_one - q_two)*np.pi/180\n",
    "        lat_diff = (p_one - p_two)*np.pi/180\n",
    "        a = np.sin(lat_diff/2)**2 + np.cos(p_one*np.pi/180)*np.cos(p_two*np.pi/180)*(np.sin(lon_diff/2)**2)\n",
    "        c = np.arctan2(np.sqrt(a), np.sqrt(1 - a))\n",
    "        d = 6371.00*float(c)\n",
    "        return tuple(list(x) + [d])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "spql_listings_and_parks_info_rdd = spql_listings_and_parks_info_rdd.map(distance_calculation)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[(11204286,\n",
       "  -117.00194036983295,\n",
       "  32.581881678016465,\n",
       "  0,\n",
       "  -117.113,\n",
       "  32.708,\n",
       "  8.729150422837035),\n",
       " (11204286,\n",
       "  -117.00194036983295,\n",
       "  32.581881678016465,\n",
       "  1,\n",
       "  -117.161,\n",
       "  32.708,\n",
       "  10.228095266922994)]"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "spql_listings_and_parks_info_rdd.take(2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "schema_three = StructType([StructField(\"id\", IntegerType(), True),\n",
    "                    StructField(\"longitude\", DoubleType(), True),\n",
    "                    StructField(\"latitude\", DoubleType(), True)] + [StructField(\"park_id\", IntegerType(), True),\n",
    "                    StructField(\"park_longitude\", DoubleType(), True),\n",
    "                    StructField(\"park_latitude\", DoubleType(), True), StructField(\"distance\", DoubleType(), True)])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "spql_listings_and_parks_info_df = sqlContext.createDataFrame(spql_listings_and_parks_info_rdd, schema_three)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "spql_listings_and_parks_info_rdd = spql_listings_and_parks_info_df.rdd.map(lambda row: (row.id, row.longitude, row.latitude, row.park_id, row.park_longitude, row.park_latitude, row.distance))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "close_parks_count = spql_listings_and_parks_info_rdd.filter(lambda x: x[-1] <= 16).map(lambda x: (x[0], 1)).reduceByKey(lambda x, y : x + y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "closest_park_distance = spql_listings_and_parks_info_rdd.map(lambda x: (x[0], x[-1])).reduceByKey(lambda x, y : min(x, y))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "park_distance  = closest_park_distance.map(lambda x: x[1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[0.4226653619251699,\n",
       " 0.22449796494527174,\n",
       " 0.40689894777771984,\n",
       " 0.25248363187723993,\n",
       " 0.2598624210631214]"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "park_distance.take(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "close_parks_count_one = spql_listings_and_parks_info_rdd.filter(lambda x: x[-1] <= 1).map(lambda x: (x[0], 1)).reduceByKey(lambda x, y : x + y)\n",
    "close_parks_count_three = spql_listings_and_parks_info_rdd.filter(lambda x: x[-1] <= 3).map(lambda x: (x[0], 1)).reduceByKey(lambda x, y : x + y)\n",
    "close_parks_count_five = spql_listings_and_parks_info_rdd.filter(lambda x: x[-1] <= 5).map(lambda x: (x[0], 1)).reduceByKey(lambda x, y : x + y)\n",
    "close_parks_count_ten = spql_listings_and_parks_info_rdd.filter(lambda x: x[-1] <= 10).map(lambda x: (x[0], 1)).reduceByKey(lambda x, y : x + y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "close_parks_count_three_value = close_parks_count_three.map(lambda x: x[1])\n",
    "close_parks_count_five_value = close_parks_count_five.map(lambda x: x[1])\n",
    "close_parks_count_ten_value = close_parks_count_ten.map(lambda x: x[1])\n",
    "close_parks_count_value = close_parks_count.map(lambda x: x[1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "count = 1\n",
    "Writer = pd.ExcelWriter('listings_parks_information_two.xlsx')\n",
    "\n",
    "for w in [close_parks_count_one, close_parks_count_three, close_parks_count_five, close_parks_count_ten, close_parks_count, closest_park_distance]:\n",
    "    listings_parks_information = w.toDF().toPandas()\n",
    "    listings_parks_information.to_excel(Writer, 'Sheet' + str(count))\n",
    "    count = count + 1\n",
    "    \n",
    "Writer.save()"
   ]
  }
 ],
 "metadata": {
  "anaconda-cloud": {},
  "kernelspec": {
   "display_name": "Python [default]",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
